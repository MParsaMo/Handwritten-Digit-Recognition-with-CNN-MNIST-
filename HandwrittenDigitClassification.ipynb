{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbwUE38HmawxxGlbauk/yb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MParsaMo/Handwritten-Digit-Recognition-with-CNN-MNIST-/blob/main/HandwrittenDigitClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split # Import for splitting data\n",
        "\n",
        "# loading data\n",
        "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Split the original training data into training and validation sets\n",
        "# A common split is 80% for training and 20% for validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "# our data shape\n",
        "print('x_train.shape:', x_train.shape) # Now smaller\n",
        "print('y_train.shape:', y_train.shape)\n",
        "print('x_val.shape:', x_val.shape)    # New validation set\n",
        "print('y_val.shape:', y_val.shape)\n",
        "print('x_test.shape:', x_test.shape) # This is the final, unseen test set\n",
        "print('y_test.shape:', y_test.shape)\n",
        "\n",
        "# showing the first image in our x_train dataset\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.title('Digit: '+ str(y_train[0]))\n",
        "plt.show()\n",
        "\n",
        "# Reshape for CNN\n",
        "features_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "features_val = x_val.reshape(x_val.shape[0], 28, 28, 1) # Reshape validation features\n",
        "features_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Normalize features\n",
        "features_train = features_train.astype('float32') / 255\n",
        "features_val = features_val.astype('float32') / 255 # Normalize validation features\n",
        "features_test = features_test.astype('float32') / 255\n",
        "\n",
        "print('features_train.shape:', features_train.shape)\n",
        "\n",
        "# One-hot encode targets\n",
        "target_train = to_categorical(y_train, 10)\n",
        "target_val = to_categorical(y_val, 10)     # One-hot encode validation targets\n",
        "target_test = to_categorical(y_test, 10)\n",
        "\n",
        "#creating our model (unchanged)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=(1, 1), input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=(1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=(1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=(1, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(features_train, target_train, epochs=10, batch_size=128, validation_data=(features_val, target_val))\n",
        "\n",
        "# evaluate on the test set\n",
        "score = model.evaluate(features_test, target_test, verbose=0)\n",
        "print('Final Test loss:', score[0])\n",
        "print('Final Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "K7xiby2QXgUh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc2e0d48-b591-4e3a-be6f-9d7976029ece"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (48000, 28, 28)\n",
            "y_train.shape: (48000,)\n",
            "x_val.shape: (12000, 28, 28)\n",
            "y_val.shape: (12000,)\n",
            "x_test.shape: (10000, 28, 28)\n",
            "y_test.shape: (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features_train.shape: (48000, 28, 28, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m601,834\u001b[0m (2.30 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">601,834</span> (2.30 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m598,378\u001b[0m (2.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598,378</span> (2.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,456\u001b[0m (13.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> (13.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.8849 - loss: 0.3662 - val_accuracy: 0.2628 - val_loss: 2.8312\n",
            "Epoch 2/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9832 - loss: 0.0569 - val_accuracy: 0.9878 - val_loss: 0.0370\n",
            "Epoch 3/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0412 - val_accuracy: 0.9906 - val_loss: 0.0290\n",
            "Epoch 4/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.0323 - val_accuracy: 0.9898 - val_loss: 0.0339\n",
            "Epoch 5/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0265 - val_accuracy: 0.9918 - val_loss: 0.0265\n",
            "Epoch 6/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0244 - val_accuracy: 0.9900 - val_loss: 0.0345\n",
            "Epoch 7/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0221 - val_accuracy: 0.9910 - val_loss: 0.0307\n",
            "Epoch 8/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0219 - val_accuracy: 0.9908 - val_loss: 0.0277\n",
            "Epoch 9/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0174 - val_accuracy: 0.9918 - val_loss: 0.0281\n",
            "Epoch 10/10\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0158 - val_accuracy: 0.9921 - val_loss: 0.0262\n",
            "Final Test loss: 0.020962413400411606\n",
            "Final Test accuracy: 0.9929999709129333\n"
          ]
        }
      ]
    }
  ]
}